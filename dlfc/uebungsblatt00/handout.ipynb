{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungsblatt 00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dieser Code importiert zwei Bibliotheken: [PyTorch](https://pytorch.org/) und [Numpy](https://numpy.org/). PyTorch ist eine Bibliothek für maschinelles Lernen und die Deep Learning Bibliothek der Wahl in unserer Vorlesung. Numpy ist eine Bibliothek für wissenschaftliche Berechnung und implementiert viele der gängigen Algorithmen für Lineare Algebra.\n",
    "\n",
    "**Aufgabe**: Führen Sie diese Zelle einmal zu Beginn der Übung aus damit die Bibliotheken importiert werden."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-16T23:17:01.312975Z",
     "start_time": "2024-06-16T23:17:00.030827Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe 4\n",
    "\n",
    "Das zentrale Objekt das von den meisten Operationen in PyTorch verwendet wird sind Instanzen der $\\texttt{torch.Tensor}$ Klasse. Die [Dokumentation](https://pytorch.org/docs/stable/tensors.html#torch.Tensor) beschreibt ein Tensor-Objekt als \"eine mehrdimensionale Matrix, die Elemente eines einzigen Datentyps enthält.\" Die folgenden Aufgaben werden Sie mit dem Erstellen, dem Auslesen wichtiger Eigenschaften und dem Modifizieren von Tensorobjekten vertraut machen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimension, Form und Datentyp\n",
    "\n",
    "Die zu den wichtigsten Attributen der Tensor Klasse gehört die Anzahl an Dimensionen $\\texttt{torch.Tensor.dim()}$, die Form des Tensors $\\texttt{torch.Tensor.shape}$ und der Datentyp der Einträgen $\\texttt{torch.Tensor.dtype}$. \n",
    "\n",
    "**Aufgabe**: Gebe Sie die [Dimension](https://pytorch.org/docs/stable/generated/torch.Tensor.dim.html), die [Form](https://pytorch.org/docs/stable/generated/torch.Tensor.size.html) und den [Datentyp](https://pytorch.org/docs/stable/tensor_attributes.html?highlight=dtype#torch.torch.dtype) der Einträge des Tensors $\\texttt{th\\_tensor}$ aus."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-06-16T23:17:05.122818Z",
     "start_time": "2024-06-16T23:17:05.110486Z"
    }
   },
   "source": [
    "th_tensor = torch.tensor([[1.], [2.], [3.]])\n",
    "\n",
    "print(f\"Dimension of tensor: {th_tensor.dim()}\")\n",
    "print(f\"Size of tensor: {th_tensor.size()}\")\n",
    "print(f\"Type of tensor: {th_tensor.dtype}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of tensor: 2\n",
      "Size of tensor: torch.Size([3, 1])\n",
      "Type of tensor: torch.float32\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zugriff und Manipulation von Tensoreinträgen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zugriff und Manipulation mit Slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python können wir auf das i-te Element einer Liste $\\texttt{L}$ mit $\\texttt{L[i]}$ zugreifen. Hier sind auch negative Indices erlaubt wobei $-1$ dem Index des letzten Elements der Liste entspricht, $-2$ dem Index des vorletzten Elements, usw. Falls wir nicht nur auf einzelne Elemente sondern auf eine Teilliste zugreifen wollen erlaubt Python dies mit Hilfe von ``Slices''. Einen (strided) Slice einer Liste erhält man mit $\\texttt{L[begin:end:step]}$.\n",
    "\n",
    "PyTorch verallgemeinert diese Konzepte auf $n$-dimensionale Tensoren. Sei nun $\\texttt{T}$ ein Tensor mit 3 Dimensionen und der Form $(d_1,d_2,d_3)$. Einfacher Zugriff $\\texttt{T[i]}$ gibt in diesem Beispiel die i-te Matrix mit Größe $d_2$ x $d_3$ als torch.Tensor zurück. Wenn wir nun auf den Eintrag $(j,k)$ in dieser Matrix zugreifen wollen so ist dies möglich mit $\\texttt{T[i,j,k]}$ wobei $\\texttt{i,j,k}$ Integer sind und wir den k-ten Eintrag der j-ten Zeile in der i-ten Matrix als torch.Tensor erhalten.\n",
    "\n",
    "Auch PyTorch unterstütz Slices allerdings ist es möglich einen Slice pro Dimension zu definieren, wobei wir für jede Dimension einen Slice mit dem obigen Syntax $\\texttt{[start:stop:step]}$ verwenden. Schauen wir uns dazu einige Beispiele an:\n",
    "\n",
    " * $\\texttt{T[2:5:1]}$ gibt eine Tensor zurück, der die Matrizen mit Index 2 bis 4 enthält. Dieser Ausdruck kann auch verkürzt werden zu $\\texttt{T[2:5]}$.\n",
    " * $\\texttt{T[0:d\\_1:2]}$ gibt eine Tensor zurück, die jede Matrix mit geradem Index enthält. Dieser Ausdruck kann auch verkürzt werden zu $\\texttt{T[::2]}$.\n",
    " * $\\texttt{T[::-1]}$ gibt eine Tensor zurück, der alle Matrizen enthält allerdings wurde ihre Reihenfolge umgekehrt.\n",
    " * $\\texttt{T[2:5, 0:d\\_2:1, 0:2:1]}$ gibt eine Tensor zurück, der nur die ersten zwei Spalten der Matrizen mit Index 2 bis 4 enthält. Dieser Ausdruck kann auch verkürzt werden zu $\\texttt{T[2:5,:,:2]}$.\n",
    "\n",
    "Für einen n-dimensionalen Tensor $\\texttt{T}$ der Größe $d_1$ x $d_2$ x ... x $d_n$ ist die allgemeine Form der Slices dementsprechend $\\texttt{T[}b_1:e_1:s_1,b_2:e_2,s_2, ..., b_n:e_n:s_n\\texttt{]}$ wobei $b_i, e_i \\in [0:d_i-1]$ mit $b_i < e_i$ und $s_i \\in \\mathbb{Z}$. Wenn $s_i = 0$ oder $e_i = d_i-1$ müssen wir diese nicht explizit angeben und sollte $s_i = 1$ gelten können wir $s_i$  und den zweiten Doppelpunkt weglassen.\n",
    "\n",
    "\n",
    "**Aufgabe**: Ihre Aufgabe ist mit Hilfe Ihres neuen Wissens über Slicing folgende Einträge des  $\\texttt{th\\_batched\\_matrices}$ auszugeben:\n",
    "1. Geben Sie das erste und das letzte Element des Tensors aus.\n",
    "2. Geben Sie die erste und die zweite Matrix des Tensors aus.\n",
    "3. Geben Sie die obere linke 2x2-Untermatrix jeder Matrix des Tensors aus.\n",
    "4. Geben Sie die dritte Spalte jeder Matrix des Tensors aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erstes und letzes Element des Tensors: tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])tensor([[82, 83, 84],\n",
      "        [85, 86, 87],\n",
      "        [88, 89, 90]])\n",
      "Erstes und zweites Element des Tensors: tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])tensor([[10, 11, 12],\n",
      "        [13, 14, 15],\n",
      "        [16, 17, 18]])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [ 7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[19, 20, 21],\n",
      "         [22, 23, 24],\n",
      "         [25, 26, 27]],\n",
      "\n",
      "        [[28, 29, 30],\n",
      "         [31, 32, 33],\n",
      "         [34, 35, 36]],\n",
      "\n",
      "        [[37, 38, 39],\n",
      "         [40, 41, 42],\n",
      "         [43, 44, 45]],\n",
      "\n",
      "        [[46, 47, 48],\n",
      "         [49, 50, 51],\n",
      "         [52, 53, 54]],\n",
      "\n",
      "        [[55, 56, 57],\n",
      "         [58, 59, 60],\n",
      "         [61, 62, 63]],\n",
      "\n",
      "        [[64, 65, 66],\n",
      "         [67, 68, 69],\n",
      "         [70, 71, 72]],\n",
      "\n",
      "        [[73, 74, 75],\n",
      "         [76, 77, 78],\n",
      "         [79, 80, 81]],\n",
      "\n",
      "        [[82, 83, 84],\n",
      "         [85, 86, 87],\n",
      "         [88, 89, 90]]])\n",
      "obere linke 2x2-Untermatrix jeder Matrix des Tensors: tensor([[[ 1,  2],\n",
      "         [ 4,  5]],\n",
      "\n",
      "        [[10, 11],\n",
      "         [13, 14]],\n",
      "\n",
      "        [[19, 20],\n",
      "         [22, 23]],\n",
      "\n",
      "        [[28, 29],\n",
      "         [31, 32]],\n",
      "\n",
      "        [[37, 38],\n",
      "         [40, 41]],\n",
      "\n",
      "        [[46, 47],\n",
      "         [49, 50]],\n",
      "\n",
      "        [[55, 56],\n",
      "         [58, 59]],\n",
      "\n",
      "        [[64, 65],\n",
      "         [67, 68]],\n",
      "\n",
      "        [[73, 74],\n",
      "         [76, 77]],\n",
      "\n",
      "        [[82, 83],\n",
      "         [85, 86]]])\n",
      "Jede Dritte Spalte jeder Matrix jedes Tensors: tensor([[ 3,  6,  9],\n",
      "        [12, 15, 18],\n",
      "        [21, 24, 27],\n",
      "        [30, 33, 36],\n",
      "        [39, 42, 45],\n",
      "        [48, 51, 54],\n",
      "        [57, 60, 63],\n",
      "        [66, 69, 72],\n",
      "        [75, 78, 81],\n",
      "        [84, 87, 90]])\n"
     ]
    }
   ],
   "source": [
    "th_batched_matrices = torch.arange(1,91).reshape([10,3,3])\n",
    "print(f\"Erstes und letzes Element des Tensors: {th_batched_matrices[0]}{th_batched_matrices[-1]}\")\n",
    "print(f\"Erstes und zweites Element des Tensors: {th_batched_matrices[0]}{th_batched_matrices[1]}\")\n",
    "print(th_batched_matrices)\n",
    "print(f\"obere linke 2x2-Untermatrix jeder Matrix des Tensors: {th_batched_matrices[:,:2,:2]}\")\n",
    "print(f\"Jede Dritte Spalte jeder Matrix jedes Tensors: {th_batched_matrices[:,:,2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boolean Array Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boolean Indexing ist eine Technik, um Elemente aus einem Tensor in PyTorch auszuwählen, die einer bestimmten Bedingung entsprechen. Dabei wird ein Tensor mit booleschen Werten (True oder False) verwendet, der die gleiche Form wie der ursprüngliche Tensor hat. Nur die Elemente, die an den Positionen True sind, werden ausgewählt. Ein kurzes Beispiel ist:\n",
    "\n",
    "```python\n",
    "    # Erstellen eines Tensors mit zufälligen Zahlen\n",
    "    x = torch.randn(3, 4)\n",
    "\n",
    "    # Erstellen eines booleschen Tensors mit der Bedingung x > 0\n",
    "    mask = x > 0\n",
    "\n",
    "    # Auswählen der Elemente aus x, die der Bedingung entsprechen\n",
    "    y = x[mask]\n",
    "```\n",
    "\n",
    "**Aufgabe**: Verwenden Sie von Boolean Array Indexing um alle negativen Einträge in den Matrizen im Tensor $\\texttt{th\\_batched\\_matrices}$ durch Nullen ersetzen. Geben Sie die fünfte und sechste Matrizen vor und nach dem Ändern der Einträge sowie die Form und den Datentyp der Einträge der bool Maske aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-45, -44, -43],\n",
      "         [-42, -41, -40],\n",
      "         [-39, -38, -37]],\n",
      "\n",
      "        [[-36, -35, -34],\n",
      "         [-33, -32, -31],\n",
      "         [-30, -29, -28]],\n",
      "\n",
      "        [[-27, -26, -25],\n",
      "         [-24, -23, -22],\n",
      "         [-21, -20, -19]],\n",
      "\n",
      "        [[-18, -17, -16],\n",
      "         [-15, -14, -13],\n",
      "         [-12, -11, -10]],\n",
      "\n",
      "        [[ -9,  -8,  -7],\n",
      "         [ -6,  -5,  -4],\n",
      "         [ -3,  -2,  -1]],\n",
      "\n",
      "        [[  0,   1,   2],\n",
      "         [  3,   4,   5],\n",
      "         [  6,   7,   8]],\n",
      "\n",
      "        [[  9,  10,  11],\n",
      "         [ 12,  13,  14],\n",
      "         [ 15,  16,  17]],\n",
      "\n",
      "        [[ 18,  19,  20],\n",
      "         [ 21,  22,  23],\n",
      "         [ 24,  25,  26]],\n",
      "\n",
      "        [[ 27,  28,  29],\n",
      "         [ 30,  31,  32],\n",
      "         [ 33,  34,  35]],\n",
      "\n",
      "        [[ 36,  37,  38],\n",
      "         [ 39,  40,  41],\n",
      "         [ 42,  43,  44]]])\n",
      "Vor den änderungen:tensor([[[-9, -8, -7],\n",
      "         [-6, -5, -4],\n",
      "         [-3, -2, -1]],\n",
      "\n",
      "        [[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8]]])\n",
      "Nach den änderungen:tensor([[[0, 0, 0],\n",
      "         [0, 0, 0],\n",
      "         [0, 0, 0]],\n",
      "\n",
      "        [[0, 1, 2],\n",
      "         [3, 4, 5],\n",
      "         [6, 7, 8]]])\n",
      "torch.bool\n",
      "torch.Size([10, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "th_batched_matrices = torch.arange(-45,45).reshape([10,3,3])\n",
    "print(th_batched_matrices)\n",
    "print(f\"Vor den änderungen:{th_batched_matrices[4:6]}\")\n",
    "x = torch.zeros(3, 4)\n",
    "mask = th_batched_matrices < 0\n",
    "\n",
    "# Auswählen und Ersetzen aller negativen Werte durch Nullen\n",
    "th_batched_matrices[mask] = 0\n",
    "print(f\"Nach den änderungen:{th_batched_matrices[4:6]}\")\n",
    "print(mask.dtype)\n",
    "print(mask.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integer Array Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um auf Einträge eines Pytorch Tensors mit Hilfe einer Liste von Indices zuzugreifen, kann man die Liste als Index für den Tensor verwenden. Dies gibt einen neuen Tensor zurück, der die Elemente an den angegebenen Indices enthält. Dies funktioniert sowohl für eindimensionale als auch für mehrdimensionale Tensoren. \n",
    "\n",
    "**Aufgabe**: Im Beispiel wird ein dreidimensionaler Tensor mit 10 Matrizen der Größe 3x3 erstellt und dann mit einer Liste von Indices [1, 2, 3, 5, 8] indiziert. Das Ergebnis ist ein neuer Tensor mit 5 Matrizen der Größe 3x3, die den Einträgen an den geraden Indices des ursprünglichen Tensors entsprechen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-36, -35, -34],\n",
      "         [-33, -32, -31],\n",
      "         [-30, -29, -28]],\n",
      "\n",
      "        [[-27, -26, -25],\n",
      "         [-24, -23, -22],\n",
      "         [-21, -20, -19]],\n",
      "\n",
      "        [[-18, -17, -16],\n",
      "         [-15, -14, -13],\n",
      "         [-12, -11, -10]],\n",
      "\n",
      "        [[  0,   1,   2],\n",
      "         [  3,   4,   5],\n",
      "         [  6,   7,   8]],\n",
      "\n",
      "        [[ 27,  28,  29],\n",
      "         [ 30,  31,  32],\n",
      "         [ 33,  34,  35]]])\n"
     ]
    }
   ],
   "source": [
    "th_batched_matrices = torch.arange(-45,45).reshape([10,3,3])\n",
    "print(th_batched_matrices[[1,2,3,5,8]])\n",
    "\n",
    "# Begin eurer Lösung:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grundlegende Operationen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementare Funktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selbstverständlich unterstützt PyTorch elementare Operatoren $+,-,*,/$ (und noch einige weitere) zwischen mit zwei Tensoren der gleichen Größe oder einem Tensor und einem Skalar. In beiden Fällen handelt es sich um elementweise Operationen auf den Einträgen des Tensors. Um uns davon zu überzeugen, dass sich die Operatoren verhalten wie wir erwarten bearbeiten Sie bitte die folgende Aufgabe:\n",
    "\n",
    "**Aufgabe**:  Führen Sie die folgenden Operationen durch und geben Sie den resultierenden Tensor aus:\n",
    "\n",
    "1. Die Summe aus $\\texttt{th\\_tensor1}$ und $\\texttt{th\\_tensor2}$ und $\\texttt{th\\_tensor1}$ und dem Skalar $\\texttt{constant}$.\n",
    "2. Die Differenz zwischen $\\texttt{th\\_tensor1}$ und $\\texttt{th\\_tensor2}$ und $\\texttt{th\\_tensor1}$ und dem Skalar $\\texttt{constant}$.\n",
    "3. Das Produkt zwischen $\\texttt{th\\_tensor1}$ und $\\texttt{th\\_tensor2}$ und $\\texttt{th\\_tensor1}$ und dem Skalar $\\texttt{constant}$.\n",
    "4. Der Quotient zwischen $\\texttt{th\\_tensor1}$ und $\\texttt{th\\_tensor2}$ und $\\texttt{th\\_tensor1}$ und dem Skalar $\\texttt{constant}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summe aus th_tensor1 und th_tensor2: tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "Summe aus th_tensor1 und constant: tensor([[11., 11.],\n",
      "        [11., 11.]])\n",
      "Differenz aus th_tensor1 und th_tensor2: tensor([[-1., -1.],\n",
      "        [-1., -1.]])\n",
      "Differenz aus th_tensor1 und constant: tensor([[-9., -9.],\n",
      "        [-9., -9.]])\n",
      "Produkt aus th_tensor1 und th_tensor2: tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "Summe aus th_tensor1 und constant: tensor([[10., 10.],\n",
      "        [10., 10.]])\n",
      "Summe aus th_tensor1 und th_tensor2: tensor([[0.5000, 0.5000],\n",
      "        [0.5000, 0.5000]])\n",
      "Summe aus th_tensor1 und constant: tensor([[0.1000, 0.1000],\n",
      "        [0.1000, 0.1000]])\n"
     ]
    }
   ],
   "source": [
    "th_tensor1 = torch.ones([2,2])\n",
    "th_tensor2 = torch.full([2,2], 2)\n",
    "constant = 10.0\n",
    "print(f\"Summe aus th_tensor1 und th_tensor2: {th_tensor1 + th_tensor2}\")\n",
    "print(f\"Summe aus th_tensor1 und constant: {th_tensor1 + constant}\") \n",
    "print(f\"Differenz aus th_tensor1 und th_tensor2: {th_tensor1 - th_tensor2}\")\n",
    "print(f\"Differenz aus th_tensor1 und constant: {th_tensor1 - constant}\") \n",
    "print(f\"Produkt aus th_tensor1 und th_tensor2: {th_tensor1 * th_tensor2}\")\n",
    "print(f\"Summe aus th_tensor1 und constant: {th_tensor1 * constant}\") \n",
    "print(f\"Summe aus th_tensor1 und th_tensor2: {th_tensor1 / th_tensor2}\")\n",
    "print(f\"Summe aus th_tensor1 und constant: {th_tensor1 / constant}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konstruktionen von Tensoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manuelles Erzeugen von Tensoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt eine Vielzahl von Möglichkeiten um einen Tensor selbst zu erzeugen. Hier wollen wir uns nur vier gängige Methoden anschauen:\n",
    "\n",
    " * [torch.from_numpy()](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - Diese Methode erzeugt einen Tensor aus einem bestehenden Numpy-Array. Der Tensor teilt sich den Speicher mit dem Array, so dass Änderungen an einem sich auf das andere auswirken.\n",
    " * [torch.tensor()](https://pytorch.org/docs/stable/generated/torch.tensor.html) - Diese Methode erzeugt einen Tensor aus einer Numpy-Array, Liste oder einem Tupel von Werten. Der Tensor hat einen eigenen Speicher und ist unabhängig von der Eingabe.\n",
    " * [torch.rand()](https://pytorch.org/docs/stable/generated/torch.rand.html) - Diese Methode erzeugt einen Tensor mit zufälligen Werten aus einer gleichmäßigen Verteilung zwischen 0 und 1. Die Größe des Tensors muss als Argument angegeben werden.\n",
    " * [torch.randn()](https://pytorch.org/docs/stable/generated/torch.randn.html) - Diese Methode erzeugt einen Tensor mit zufälligen Werten aus einer Normalverteilung mit Mittelwert 0 und Standardabweichung 1. Die Größe des Tensors muss als Argument angegeben werden.\n",
    "\n",
    "**Aufgabe**: Verwenden Sie die oben genannten Möglichkeiten wie folgt um Tensoren zu erstellen:\n",
    "\n",
    " 1. Erzeugen Sie einen $\\texttt{torch.Tensor}$ aus dem Numpy-Array $\\texttt{np\\_array}$, indem Sie die Funktion torch.from_numpy().\n",
    " 2. Verwenden Sie torch.tensor() um einen Tensor zu erzeugen der die Einträge 1,2,3 hat.\n",
    " 3. Erstellen Sie eine 2x2 Matrix als $\\texttt{torch.Tensor}$, die mit gleichverteilen Werten zwischen 0 und 1 gefüllt ist.\n",
    " 4. Erstellen Sie eine 2x2 Matrix als $\\texttt{torch.Tensor}$, die mit normalverteilten Werten gefüllt ist\n",
    "\n",
    "Geben Sie den resultierenden Tensor für jede der vier Teilaufgaben aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:tensor([1., 2., 3.], dtype=torch.float64)\n",
      "2:tensor([1, 2, 3])\n",
      "3:tensor([[0.3226, 0.3593],\n",
      "        [0.4753, 0.1974]])\n",
      "4:tensor([[-0.1957,  0.3831],\n",
      "        [ 0.8262, -1.3012]])\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array([1., 2., 3.])\n",
    "print(f\"1:{torch.from_numpy(np_array)}\")\n",
    "print(f\"2:{torch.tensor([1,2,3])}\")\n",
    "print(f\"3:{torch.rand(2,2)}\")\n",
    "print(f\"4:{torch.randn(2,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Konstruktion mit Concatination und Stack."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion [torch.cat()](https://pytorch.org/docs/stable/generated/torch.cat.html) dient dazu, mehrere Tensoren entlang einer bestimmten Dimension zu einem einzigen Tensor zu verbinden. Die Tensoren müssen die gleiche Form haben, außer in der Dimension, entlang derer sie verbunden werden. Die Funktion nimmt als Argumente eine Sequenz von Tensoren und die Dimension, entlang derer sie verbunden werden sollen. Die Funktion gibt einen neuen Tensor zurück, der die Elemente aller Eingabetensoren enthält.\n",
    "\n",
    "Die Funktion [torch.stack()](https://pytorch.org/docs/stable/generated/torch.stack.html) erlaubt es, mehrere Tensoren entlang einer neuen Dimension zu stapeln. Dabei müssen alle Tensoren die gleiche Größe und den gleichen Datentyp haben. Die neue Dimension wird an der angegebenen Position eingefügt, die standardmäßig 0 ist. Das Ergebnis ist ein Tensor mit einer zusätzlichen Dimension, deren Größe der Anzahl der gestapelten Tensoren entspricht.\n",
    "\n",
    "**Aufgabe**: Gegeben sind drei Matrizen $\\texttt{th\\_matrix1}$, $\\texttt{th\\_matrix2}$ und $\\texttt{th\\_matrix3}$ mit der gleichen Anzahl von Spalten, aber unterschiedlichen Anzahlen von Zeilen. Schreiben Sie ein Programm, das die folgenden Operationen ausführt:\n",
    "\n",
    "- Verbinden Sie die drei Matrizen entlang der Zeilenachse zu einer neuen Matrix und geben Sie deren Form aus.\n",
    "- Verbinden Sie die drei Matrizen entlang der Spaltenachse zu einer neuen Matrix und geben Sie deren Form aus.\n",
    "- Stapeln Sie die drei Matrizen entlang der ersten Dimension zu einem neuen Tensor und geben Sie dessen Form aus.\n",
    "- Stapeln Sie die drei Matrizen entlang der zweiten Dimension zu einem neuen Tensor und geben Sie dessen Form aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4179, 0.8594, 0.0253, 0.5742, 0.6273, 0.5988],\n",
      "        [0.3161, 0.8945, 0.0948, 0.9913, 0.6722, 0.3188],\n",
      "        [0.8797, 0.8752, 0.7956, 0.2912, 0.4927, 0.6870],\n",
      "        [0.4774, 0.7755, 0.0680, 0.9760, 0.1713, 0.2783],\n",
      "        [0.4307, 0.8268, 0.0570, 0.1028, 0.6850, 0.1255],\n",
      "        [0.9201, 0.1764, 0.2081, 0.7721, 0.9515, 0.0597],\n",
      "        [0.0248, 0.8541, 0.4131, 0.2921, 0.8528, 0.8279],\n",
      "        [0.4211, 0.7577, 0.8524, 0.6017, 0.3632, 0.0722],\n",
      "        [0.8251, 0.3525, 0.7390, 0.7291, 0.8778, 0.3555],\n",
      "        [0.2040, 0.6416, 0.2577, 0.7211, 0.7072, 0.1950],\n",
      "        [0.8406, 0.1912, 0.0556, 0.5300, 0.5785, 0.2794],\n",
      "        [0.5464, 0.3970, 0.7251, 0.2577, 0.6609, 0.0567],\n",
      "        [0.5127, 0.3242, 0.7481, 0.5588, 0.2536, 0.6451],\n",
      "        [0.5039, 0.0673, 0.5155, 0.2380, 0.4404, 0.1681],\n",
      "        [0.5935, 0.9440, 0.0631, 0.3909, 0.7400, 0.8173]])\n",
      "tensor([[[0.4179, 0.8594, 0.0253, 0.5742, 0.6273, 0.5988],\n",
      "         [0.3161, 0.8945, 0.0948, 0.9913, 0.6722, 0.3188],\n",
      "         [0.8797, 0.8752, 0.7956, 0.2912, 0.4927, 0.6870],\n",
      "         [0.4774, 0.7755, 0.0680, 0.9760, 0.1713, 0.2783],\n",
      "         [0.4307, 0.8268, 0.0570, 0.1028, 0.6850, 0.1255]],\n",
      "\n",
      "        [[0.9201, 0.1764, 0.2081, 0.7721, 0.9515, 0.0597],\n",
      "         [0.0248, 0.8541, 0.4131, 0.2921, 0.8528, 0.8279],\n",
      "         [0.4211, 0.7577, 0.8524, 0.6017, 0.3632, 0.0722],\n",
      "         [0.8251, 0.3525, 0.7390, 0.7291, 0.8778, 0.3555],\n",
      "         [0.2040, 0.6416, 0.2577, 0.7211, 0.7072, 0.1950]],\n",
      "\n",
      "        [[0.8406, 0.1912, 0.0556, 0.5300, 0.5785, 0.2794],\n",
      "         [0.5464, 0.3970, 0.7251, 0.2577, 0.6609, 0.0567],\n",
      "         [0.5127, 0.3242, 0.7481, 0.5588, 0.2536, 0.6451],\n",
      "         [0.5039, 0.0673, 0.5155, 0.2380, 0.4404, 0.1681],\n",
      "         [0.5935, 0.9440, 0.0631, 0.3909, 0.7400, 0.8173]]])\n"
     ]
    }
   ],
   "source": [
    "th_matrix1 = torch.rand([5,6])\n",
    "th_matrix2 = torch.rand([5,6])\n",
    "th_matrix3 = torch.rand([5,6])\n",
    "print(torch.cat((th_matrix1,th_matrix2,th_matrix3)))\n",
    "print(torch.stack((th_matrix1,th_matrix2,th_matrix3)))\n",
    "# Begin eurer Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datentypkonvertierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Einträge eines Tensors haben einen bestimmten Datentyp, wie z.B. torch.float32, torch.uint8 oder torch.bool. Der Datentyp der Einträge kann großen Einfluss auf die Performance haben, da er bestimmt, wie viel Speicherplatz ein Tensor benötigt und welche Operationen auf ihm ausgeführt werden können. Nicht alle Operationen sind für alle Datentypen implementiert.\n",
    "\n",
    "Die Typkonvertierung der Einträge eines Tensors wird mit der Funktion [torch.Tensor.to()](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) durchgeführt. Diese Methode nimmt einen den neuen Datentyp als Argument und gibt einen neuen Tensor dessen Einträge den gewünschten Datentyp haben zurück. Zum Beispiel kann man einen Tensor mit float-Einträgen in einen Tensor mit int-Einträgen konvertieren, indem man .to(torch.int) aufruft.\n",
    "\n",
    "Datentypenkonvertierung in Pytorch wird häufig gebraucht beim Laden von Datensätzen, da die Daten oft in verschiedenen Formaten vorliegen. Zum Beispiel können Bilder als uint8-Werte gespeichert sein, die zwischen 0 und 255 liegen. Um diese Daten für das Training eines neuronalen Netzes zu verwenden, bietet es sich an dass wir sie in float-Werte konvertieren, die zwischen 0 und 1 liegen. Dies kann man mit der Methode $\\texttt{.to(torch.float32)}$ und einer Division durch 255 erreichen.\n",
    "\n",
    "**Aufgabe**: Geben Sie den Datentyp der Einträge der Tensoren $\\texttt{np\\_tensor}$ und $\\texttt{th\\_tensor}$ aus. Konvertieren Sie die Datentype der Tensoren zu $\\texttt{torch.float32}$ und geben Sie den Datentypen erneut aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.float32\n",
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array([1., 2., 3.])\n",
    "np_tensor = torch.from_numpy(np_array)\n",
    "th_tensor = torch.tensor([1., 2., 3.])\n",
    "print(np_tensor.dtype)\n",
    "np_tensor_float32 = np_tensor.to(torch.float32)\n",
    "print(np_tensor_float32.dtype)\n",
    "print(th_tensor.dtype)\n",
    "th_tensor_float32 = th_tensor.to(torch.float32)\n",
    "print(th_tensor_float32.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grundlegende Funktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementweise Funktionen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elementweise Funktionen werden auf jedes Element eines Tensors angewendet werden, ohne die Form oder Dimension des Tensors zu ändern. Einige Beispiele für elementweise Funktionen sind [abs](https://pytorch.org/docs/stable/generated/torch.abs.html), [cos](https://pytorch.org/docs/stable/generated/torch.cos.html), [sin](https://pytorch.org/docs/stable/generated/torch.sin.html), [exp](https://pytorch.org/docs/stable/generated/torch.exp.html), [log](https://pytorch.org/docs/stable/generated/torch.log.html) usw. Um eine elementweise Funktion auf einen Tensor anzuwenden, muss man nur die Funktion mit dem Tensor als Argument aufrufen.\n",
    "\n",
    "**Aufgabe**: Berechnen Sie den Betrag der Werte im Tensor $\\texttt{th\\_tensor}$ und geben Sie Werte in dem resultierenden Tensor aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "th_tensor = torch.full([3], -2.0)\n",
    "print(abs(th_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionen als Argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einige Funktionen in PyTorch akzeptieren Dimensionen als optionales Argument, um eine Operation entlang einer Achsen oder mehreren Achsen eines Tensors auszuführen. Zum Beispiel kann die Funktion [torch.amin](https://pytorch.org/docs/stable/generated/torch.amin.html)/[torch.amax](https://pytorch.org/docs/stable/generated/torch.amax.html) einen Tensor als Eingabe nehmen und das Minimum bzw. Maximum entlang einer oder mehrerer Dimensionen zurückgeben. Die Funktion [torch.sum](https://pytorch.org/docs/stable/generated/torch.sum.html) kann einen Tensor als Eingabe nehmen und die Summe entlang einer oder mehrerer Dimensionen zurückgeben. Die Dimensionen werden als Liste oder Tupel von ganzen Zahlen angegeben, die die Indizes der Achsen darstellen, über die die Operation ausgeführt werden soll. Hier ist ein Beispiel:\n",
    "\n",
    "```python\n",
    "torch.sum(th_tensor, dim=[0,2])\n",
    "```\n",
    "\n",
    "**Aufgabe**: \n",
    "* Verwenden Sie amin und geben Sie den kleinsten und größten Wert des Tensor $\\texttt{th\\_tensor}$ aus.\n",
    "* Verwenden Sie amin und geben Sie den kleinsten und größten Wert des Tensors $\\texttt{th\\_tensor}$ über die letzten zwei Achsen aus.\n",
    "* Verwenden Sie sum und geben Sie die Summe aller Einträge des Tensors $\\texttt{th\\_tensor}$ aus.\n",
    "* Verwenden Sie sum um die Summe der Einträge des Tensors $\\texttt{th\\_tensor}$ über die letzten zwei Achsen zu berechnen und auszugeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-9.)\n",
      "tensor(9.)\n",
      "torch.Size([5, 2, 2])\n",
      "Kleinster und größter Wert des Tensors über die letzten zwei Achsentensor([-9.0000, -5.2105, -1.4211,  2.3684,  6.1579])tensor([-6.1579, -2.3684,  1.4211,  5.2105,  9.0000])\n",
      "tensor(-1.9073e-06)\n",
      "Summe über die letzten beiden Achsen: tensor([-30.3158, -15.1579,   0.0000,  15.1579,  30.3158])\n"
     ]
    }
   ],
   "source": [
    "th_tensor = torch.linspace(-9., 9., steps=20).reshape(5,2,2)\n",
    "print(torch.amin(th_tensor))\n",
    "print(torch.amax(th_tensor))\n",
    "print(f\"Kleinster und größter Wert des Tensors über die letzten zwei Achsen{torch.amin(th_tensor, dim=(-2, -1))}{torch.amax(th_tensor, dim=(-2, -1))}\")\n",
    "print(torch.sum(th_tensor))\n",
    "print(f\"Summe über die letzten beiden Achsen: {torch.sum(th_tensor, dim=(-2,-1))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulation der Form eines Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape/View"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[torch.reshape](https://pytorch.org/docs/stable/generated/torch.reshape.html) und [torch.Tensor.view](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) sind Funktionen, die verwendet werden, um die Form eines Tensors zu ändern wobei die Anzahl der Einträge der neuen Form und alten Form gleich sein muss.\n",
    "\n",
    "Die Funktion $\\texttt{torch.reshape}$ gibt falls möglich eine \"view\" des ursprünglichen Tensors zurück und sonst eine Kopie des Tensors. Die Funktion $\\texttt{torch.Tensor.view}$ gibt immer eine \"view\" des ursprünglichen Tensors zurück. Eine \"view\" eines Tensor ist eine Referenz auf den Speicherbereich des ursprünglichen Tensor die diesen aber in einer anderen Form darstellt.\n",
    "\n",
    "**Aufgabe**: Geben Sie die Form des Tensors $\\texttt{th\\_tensor}$ aus. Ändern Sie die Form von $\\texttt{th\\_tensor}$ in eine $3$ x $3$ Matrix und geben Sie Form des neuen Tensors aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "th_tensor = torch.arange(9)\n",
    "print(th_tensor.size())\n",
    "reshaped_th_tensor = torch.reshape(th_tensor, (3, 3))\n",
    "print(reshaped_th_tensor.size())#Begin eurer Lösung:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transponieren von Tensoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Transponieren ist eine Operation, die die Dimensionen eines Tensors vertauscht. Zum Beispiel wird ein Tensor der Form (2, 3) zu einem Tensor der Form (3, 2) transponiert. Das Transponieren kann mit der Funktion [torch.transpose](https://pytorch.org/docs/stable/generated/torch.transpose.html) durchgeführt werden, die einen \"view\" des Eingabetensors zurückgibt. Die Funktion erwartet einen Tensor so wie zwei Dimensionen die vertauscht werden sollen als Argument.\n",
    "\n",
    "\n",
    "**Aufgabe**:\n",
    " * Geben Sie die Form von $\\texttt{th\\_matrix}$ aus, transponieren Sie die Matrix in eine $2$ x $4$ Matrix und geben Sie die Form des neuen Tensors aus.\n",
    " * Geben Sie die Form von $\\texttt{th\\_batched\\_matrices}$ aus, transponieren Sie alle 10 Matrizen von $4$ x $2$ Matrizen in  $2$ x $4$ Matrizen mit einem Befehl und geben Sie die Form des neuen Tensors aus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Originale th_matrix: torch.Size([4, 2])\n",
      "Transponierte th_matrix: torch.Size([2, 4])\n",
      "Originale th_batched_matrices: torch.Size([10, 4, 2])\n",
      "Alle 10 transponiert mit 2 und 3 dim getausch: torch.Size([10, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "th_matrix = torch.rand([4, 2])\n",
    "print(f\"Originale th_matrix: {th_matrix.size()}\")\n",
    "transposed_th_matrix = torch.transpose(th_matrix,0,1)\n",
    "print(f\"Transponierte th_matrix: {transposed_th_matrix.size()}\")\n",
    "th_batched_matrices = torch.rand([10, 4, 2])\n",
    "print(f\"Originale th_batched_matrices: {th_batched_matrices.size()}\")\n",
    "transposed_th_batched_matrices = torch.transpose(th_batched_matrices,1,2)\n",
    "print(f\"Alle 10 transponiert mit 2 und 3 dim getausch: {transposed_th_batched_matrices.size()}\")\n",
    "\n",
    "#Begin eurer Lösung:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine weiter nützliche Funktion von Tensoren, ist die Möglichkeit des [Boardcasting](https://pytorch.org/docs/stable/notes/broadcasting.html#broadcasting-semantics) von Operation. Broadcasting erlaubt es eine Operation auf Tensoren unterschiedlicher Größe anzuwenden ohne die Daten vorher zu kopieren wenn die Form der Tensoren folgende Bedingungen erfüllen:\n",
    "\n",
    "+ Jeder Tensor hat mindestens eine Dimension.\n",
    "+ Bei der Iteration über die Dimensionsgrößen, beginnend mit der letzten Dimension, müssen die Dimensionsgrößen entweder gleich sein, eine von ihnen ist 1 oder eine von ihnen existiert nicht.\n",
    "    \n",
    "Wenn diese Bedingungen erfüllt sind, wird die Operation elementweise entlang der unterschiedlichen Dimensionen angewendet. \n",
    "\n",
    "**Aufgabe**: In der nächsten Codezelle sind ein paar Beispiele für Broadcasting. Einige davon scheinen aber nicht zu funktionieren. Kommentieren Sie alle Beispiele aus die nicht funktionieren und beschreiben Sie in einem weiteren Kommentar kurz warum das Beispiel. Nehmen Sie dabei Bezug auf die obenstehenden Regeln für Broadcasting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x: torch.Size([2, 3]), shape of y torch.Size([3]), shape of the resulting tensor torch.Size([2, 3])\n",
      "Beispiel 2 Klappt nicht, da die Dimensionsgrößen nicht 1 sind, aber auch beide existieren\n",
      "Shape of x: torch.Size([2, 3, 4, 5]), shape of y torch.Size([3, 1, 1]), shape of the resulting tensor torch.Size([2, 3, 4, 5])\n",
      "Shape of x: torch.Size([2, 3, 4, 5]), shape of y torch.Size([3, 1, 1]), shape of the resulting tensor torch.Size([2, 3, 4, 5])\n",
      "Beispiel 4 klappt nicht, da die Dimension von [1,1,2,3,1] nicht mit den von [2,3,4,5,1] matchen, weil 2 und 4, sowie 3 und 5 gegen die Regeln verstoßten\n"
     ]
    }
   ],
   "source": [
    "th_batched_matrices = torch.rand([10,4,2])\n",
    "th_matrix = torch.rand([4,2])\n",
    "\n",
    "# First example\n",
    "x = torch.ones(2, 3) # shape (2, 3)\n",
    "y = torch.randn(3) # shape (3)\n",
    "z = x + y # add x and y using broadcasting\n",
    "print(f\"Shape of x: {x.shape}, shape of y {y.shape}, shape of the resulting tensor {z.shape}\")\n",
    "\n",
    "# Second example\n",
    "# x = torch.ones(2, 3, 2) # shape (2, 3, 2)\n",
    "# y = torch.randn(2, 3) # shape (2, 3)\n",
    "# z = x + y # add x and y using broadcasting\n",
    "# print(f\"Shape of x: {x.shape}, shape of y {y.shape}, shape of the resulting tensor {z.shape}\")\n",
    "print(\"Beispiel 2 Klappt nicht, da die Dimensionsgrößen nicht 1 sind, aber auch beide existieren\")\n",
    "# Third example\n",
    "x = torch.ones(2, 3, 4, 5) # shape (2, 3, 4, 5)\n",
    "y = torch.randn(3, 1, 1) # shape (3, 1, 1)\n",
    "z = x + y # add them using broadcasting\n",
    "print(f\"Shape of x: {x.shape}, shape of y {y.shape}, shape of the resulting tensor {z.shape}\")\n",
    "\n",
    "# # Fourth example\n",
    "# x = torch.ones(2, 3, 4, 5, 1) # shape (2, 3, 4, 5, 1)\n",
    "# y = torch.randn(2, 3, 1) # shape (2, 3, 1)\n",
    "# z = x + y # add them using broadcasting\n",
    "print(f\"Shape of x: {x.shape}, shape of y {y.shape}, shape of the resulting tensor {z.shape}\")\n",
    "print(\"Beispiel 4 klappt nicht, da die Dimension von [1,1,2,3,1] nicht mit den von [2,3,4,5,1] matchen, weil 2 und 4, sowie 3 und 5 gegen die Regeln verstoßten\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singleton Dimensionen hinzufügen und entfernen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Broadcasting zu richtig zu nutzen ist es notwendig die Anzahl der Dimensionen kontrollieren zu können und ggf. zusätzliche \"singleton\" Dimensionen (Dimensionen deren Größe eins ist) hinzuzufügen oder entfernen zu können. Zusätzlich zu $\\texttt{torch.reshape}$ und $\\texttt{torch.Tensor.view}$ bietet PyTorch und noch zwei weiter Möglichkeiten \"singleton\" Dimensionen hinzufügen:\n",
    "\n",
    " 1. [torch.unsqueeze()](https://pytorch.org/docs/stable/generated/torch.unsqueeze.html) - fügt eine neue Dimension mit der Größe 1 an einer bestimmten Position hinzufügt. Die Funktion erwartet die Achse an der die Dimension eingefügt wird als Argument. Für einen Tensor $\\texttt{T}$ mit Form $d_1$ x $d_2$ gibt $\\texttt{T.unsqueeze(1)}$ einen Tensor zurück der eine zusätzliche Dimension zwischen $d_1$ und $d_2$ hat.\n",
    " 2. $\\texttt{None}$ - kann in der Indizierung eines Tensors verwendet werden um eine zusätzliche Dimension hinzufügen. Für einen Tensor $\\texttt{T}$ mit Form $d_1$ x $d_2$ gibt $\\texttt{T[:,None,:]}$ einen Tensor zurück der eine zusätzliche Dimension zwischen $d_1$ und $d_2$ hat.\n",
    "\n",
    "Wenn wir \"singleton\" Dimensionen entfernen wollen bietet PyTorch uns folgende Möglichkeiten:\n",
    "\n",
    " 1. [torch.squeeze()](https://pytorch.org/docs/stable/generated/torch.squeeze.html) - entfernt alle Dimensionen mit der Größe 1 aus einem Tensor falls keine Achse als Argument übergeben wird; wollen wir nur eine spezifische \"singleton\"-Dimension entfernen können wir ihren Index als Argument angeben. \n",
    " 2. Indizierung - kann ebenfalls verwendet werden um spezifische \"singleton\" Dimensionen zu entfernen. Für einen Tensor $\\texttt{T}$ mit Form $d_1$ x 1 x $d_2$ gibt $\\texttt{T[:,0,:]}$ einen Tensor mit Größe $d_1$ x $d_2$ zurück.\n",
    "\n",
    "Auch zum Entfernen von \"singleton\" Dimensionen lassen sich natürlich torch.reshape oder torch.view verwenden.\n",
    "\n",
    "**Aufgabe**: Verwenden Sie torch.squeeze und torch.unsqueeze um \"singleton\" Dimensionen zu x und y hinzufügen oder zu entfernen so dass $z = x+y$ berechnet werden kann. Geben Sie die Form des resultierenden Vektors aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones(2, 3, 4, 5, 1) # shape (2, 3, 4, 5, 1)\n",
    "y = torch.randn(1, 2, 3, 5) \n",
    "#TODO i dont get it funktioniert das hier?\n",
    "z = x + y\n",
    "# Begin eurer Lösung:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix und Vektor Produkte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch können wir fast alle Vektor/Matrix Produkte mit der Funktion [$\\texttt{torch.matmul}$](https://pytorch.org/docs/stable/generated/torch.matmul.html) berechnen. Das Verhalten der Funktion ist dabei anhängig von der Dimension der Eingabetensoren und wird von der Dokumentation wie folgt beschrieben:\n",
    "\n",
    " + Wenn beide Tensoren 1-dimensional sind, wird das Skalarprodukt zurückgegeben.\n",
    "\n",
    " + Sind beide Argumente 2-dimensional, wird das Matrix-Matrix-Produkt zurückgegeben.\n",
    "\n",
    " + Ist das erste Argument eindimensional und das zweite Argument zweidimensional, wird seiner Dimension für die Zwecke der Matrixmultiplikation eine 1 vorangestellt. Nach der Matrixmultiplikation wird die vorangestellte Dimension wieder entfernt.\n",
    "\n",
    " + Ist das erste Argument 2-dimensional und das zweite Argument 1-dimensional, wird das Matrix-Vektor-Produkt zurückgegeben.\n",
    " \n",
    " + Wenn beide Argumente mindestens 1-dimensional sind und mindestens ein Argument N-dimensional ist (wobei N > 2 ist), wird eine Multiplikation einer gepackten Matrix zurückgegeben. Ist das erste Argument eindimensional, so wird seiner Dimension für die Zwecke der Multiplikation der gepackten Matrix eine 1 vorangestellt und danach entfernt. Ist das zweite Argument eindimensional, wird seiner Dimension eine 1 vorangestellt, um die Matrix zu multiplizieren, und danach entfernt. Die Funktion verwendet broadcasting entlang der \"singleton\" Dimensionen.\n",
    "\n",
    "Der @-Operator ist äquivalent zu torch.matmul() und kann auf zwei Tensoren angewendet werden, die die gleichen Dimensionen haben oder broadcastbar sind.\n",
    "\n",
    "**Aufgabe** Gegeben ist eine Matrix $A$ und Vektoren $v_1, ..., v_5$. Verwenden Sie Ihr neues Wissen über \"singleton\" Dimensionen und Broadcasting um mit je einem matmul-Aufruf folgende Berechnung dazuführen und das Ergebnis auszugeben:\n",
    "\n",
    "1. Berechne das Skalarprodukt $\\langle v_1, v_1 \\rangle$\n",
    "2. Berechne das Matrix/Vektor Produkt $A \\cdot v$\n",
    "3. Berechne das Matrix/Matrix Produkt $A^T \\cdot A$\n",
    "4. Berechne das Matrix/Matrix Produkt $A \\cdot v_i$ für alle $i \\in [1:5]$ mit nur einem matmul Aufruf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skalarprodukt v1,v1: 1.0\n",
      "Matrixvektorprodukt A * v: tensor([1., 3., 5., 7.])\n",
      "Matrix Matrix Produkt AT * A: tensor([[56., 68.],\n",
      "        [68., 84.]])\n",
      "Matrix Matrix Produkt A * vi: (tensor([[0., 1.],\n",
      "        [2., 3.],\n",
      "        [4., 5.],\n",
      "        [6., 7.]]), tensor([[0., 1.],\n",
      "        [2., 3.],\n",
      "        [4., 5.],\n",
      "        [6., 7.],\n",
      "        [8., 9.]]))\n"
     ]
    }
   ],
   "source": [
    "th_batched_vectors = torch.arange(10, dtype=torch.float32).reshape(5,2) #Vektoren v_1, ..., v_5 in einem Tensor\n",
    "th_vector = th_batched_vectors[0] # Vektor v_1 als seperater Tensor\n",
    "th_matrix = torch.arange(8, dtype=torch.float32).reshape(4,2) # Matrix A\n",
    "print(f\"Skalarprodukt v1,v1: {th_vector @ th_vector}\")\n",
    "print(f\"Matrixvektorprodukt A * v: {th_matrix @ th_vector}\")\n",
    "print(f\"Matrix Matrix Produkt AT * A: {th_matrix.T @ th_matrix}\")\n",
    "print(f\"Matrix Matrix Produkt A * vi: {th_matrix,th_batched_vectors}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Begin euer Lösung:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "81f57b27ca37b55c596f080121424dcf7c0495475ff1affa9066a211553d9495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
